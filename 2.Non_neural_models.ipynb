{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sys\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation_utils import compare, get_accuracy, get_test_data\n",
    "from preprocessing import get_words_from_text, get_words_with_freq_from_text, file_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_VOCABULARY = \"data/text.txt\"\n",
    "TEST_DATA_PATH = \"data/aspell-60_6-normal.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_test_data(TEST_DATA_PATH, \"\\t\")\n",
    "freq_vocab = get_words_with_freq_from_text(PATH_TO_VOCABULARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Słowo bez kontekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Oto sformalizowany zapis problemu w tym przypadku:`\n",
    "\\begin{equation*}\n",
    "\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w)   \n",
    "\\end{equation*}\n",
    "\n",
    "`gdzie` $c$ `jest kandydatem na poprawną wersję napotkanego słowa` $w$ , `a` $C$ `jest zbiorem kandydatów który dalej nazywany bedzie słownikiem. `\n",
    "\n",
    "`Widząc sam wyraz` $w$ `nie jesteśmy w stanie nic powiedzieć o tym warunkowym prawdopodobieństwie.\n",
    "Na szczęście z pomocą może przyjść nam Bayes:`\n",
    "\n",
    "\\begin{equation*}\n",
    "P(c\\mid w) = \\frac{P(w \\mid c) * P(c)}{P(w)}\\\\\n",
    "\\end{equation*}\n",
    "\n",
    "`Dlatego ze` $ P(w) $ `jest wspólne dla każdego` ${c\\in C}$ `to wyżej wspomniany sformalizowany problem możemy zapisać jako:`\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w) = \\underset{c\\in C}{\\operatorname{argmax}} P(w \\mid c) * P(c)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Approches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Naiwność podejść bierze się stąd że zakładamy że każdy ze słów w słowniku ma takie samo prawdopodobieństwo wystąpienia` $P(c) = \\frac{1}{|C|}$ `oraz tego że literówka transformuje nam słowo w wyraz z poza słownika (jako że nie rozważamy kontekstu jest to całkiem odpowiednie założenie).\n",
    "Tak więc wzór redukuje nam się do:`\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w) = \\underset{c\\in C}{\\operatorname{argmax}} P(w \\mid c)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naive_approach import NaiveApproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = NaiveApproach(path_to_vocab=PATH_TO_VOCABULARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def scan_and_compare(self, word):\n",
      "        if word in self.vocab:\n",
      "            return [word]\n",
      "        candidates = [\"xxxx\"]\n",
      "        d_min = edit_distance(candidates[0], word, transpositions=True)\n",
      "        for c in self.vocab:  # c stands candidate\n",
      "            d = edit_distance(c, word, transpositions=True)\n",
      "            if d < d_min:\n",
      "                candidates = [c]\n",
      "                d_min = d\n",
      "            elif d == d_min:\n",
      "                candidates.append(c)\n",
      "        return candidates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(naive.scan_and_compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sensownym wydaje się też założyć że jeżeli popełniono literówkę to nie jest ona zaburzeniem jednocześnie pierwszej i ostatniej pozycji.\n",
    "Tak więc:`\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w) = \\underset{c\\in C}{\\operatorname{argmax}} P(w, (F(c,w)=0 \\cup  L(c,w)=0) \\mid c)\n",
    "\\end{equation*}\n",
    "\n",
    "`gdzie` $F$ `i` $L$ `to odległość między odpowiednio pierwszymi i ostatnimi znakami podanych słów`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def scan_and_compare_check_first_and_last(self, word):\n",
      "        if word in self.vocab:\n",
      "            return [word]\n",
      "        candidates = [\"xxxx\"]\n",
      "        d_min = edit_distance(candidates[0], word, transpositions=True)\n",
      "        for c in self.vocab:\n",
      "            if word[0] == c[0] or word[-1] == c[-1]:\n",
      "                d = edit_distance(c, word, transpositions=True)\n",
      "                if d < d_min:\n",
      "                    candidates = [c]\n",
      "                    d_min = d\n",
      "                elif d == d_min:\n",
      "                    candidates.append(c)\n",
      "        return candidates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(naive.scan_and_compare_check_first_and_last))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Następne podejście umożliwia nie przeglądanie całego słownika, dając szybciej wyniki, ale jedynie takie które są odległe o co najwyżej 2 od` $w$, `w metryce L-D.`<br>\n",
    "`Kandydaci są generowani w obrębie` $w$, `a następnie wyniki są filtrowane przez słownik. Zbyt mały słownik nie uchwyci pożądanego słowa, a zbyt duży zwróci wielu kandydatów.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def generate_and_scan(self, word):\n",
      "        candidates = list(known_generated(word, self.vocab))\n",
      "        if candidates:\n",
      "            return candidates\n",
      "        return [\"xxxx\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(naive.generate_and_scan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_accuracy(naive.scan_and_compare, test_data, freq_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.1276747503566334\n",
      "CPU times: user 2min 9s, sys: 781 ms, total: 2min 9s\n",
      "Wall time: 8min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6657156443176415"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(naive.scan_and_compare_check_first_and_last, test_data, freq_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.1276747503566334\n",
      "CPU times: user 2min 30s, sys: 1.27 s, total: 2min 31s\n",
      "Wall time: 2min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6678554446029482"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(naive.generate_and_scan, test_data, freq_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Założenie zaimplementowane w drugim modelu nie wydaje się ograniczające, wydaje się wręcz być żadnym ograniczeniem, gdyż wynik jest taki sam, a czas 7.5 razy szybszy.`<br>\n",
    "`Ostatni model redukujący przestrzeń kandydatów jest jednak najszybszy (~23 razy szybszy od pierwszego modelu), i ma nieco lepszy wynik, ale jest to kwestia kolejkowania się kandydatów w liście najbardziej prawdopodobnych słów.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab with Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We wcześniejszym podpunkcie zakładaliśmy takie samo prawdopodobieństwo dla każdego kandydata.`<br>\n",
    "`W tym nareszcie podejdziemy do sprawy empirycznie. Bedziemy na podstawie odpowiednio dużego tekstu zliczać wystąpienia danego kandydata i uważać stosunek liczby jego wystąpień do liczby wszystkich wyrazów jako estymacje jego prawdopodobieństwa.`\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w) = \\underset{c\\in C}{\\operatorname{argmax}} P(w \\mid c) * P(c)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from words_with_freq_approach import FrequencyApproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequnecy = FrequencyApproach(path_to_vocab=PATH_TO_VOCABULARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def scan_and_compare(self, word):\n",
      "        if word in self.vocab:\n",
      "            return [word]\n",
      "        candidates = []\n",
      "        p_max = 0\n",
      "        w_len = len(word)\n",
      "\n",
      "        for c in self.vocab:  # c stands candidate\n",
      "            d = edit_distance(c, word, transpositions=True)\n",
      "            if d < w_len:\n",
      "                p = self.vocab[c]  * (1 - (math.log(d) / math.log(w_len))) # przemyśl to\n",
      "                if p_max < p:\n",
      "                    p_max = p\n",
      "                    candidates = [c]\n",
      "                elif p_max == p:\n",
      "                    candidates.append(c)\n",
      "        if candidates:\n",
      "            return candidates\n",
      "        else:\n",
      "            return [word]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(frequnecy.scan_and_compare))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def scan_and_compare_check_first_and_last(self, word):\n",
      "        if word in self.vocab:\n",
      "            return word, 0\n",
      "        candidates = []\n",
      "        p_max = 0\n",
      "        w_len = len(word)\n",
      "        for c in self.vocab:\n",
      "            if word[0] == c[0] or word[-1] == c[-1]:\n",
      "                d = edit_distance(c, word, transpositions=True)\n",
      "                if d < w_len:\n",
      "                    p = self.vocab[c]  * (1 - (math.log(d) / math.log(w_len))) # przemyśl to\n",
      "                    if p_max < p:\n",
      "                        p_max = p\n",
      "                        candidates = [c]\n",
      "                    elif p_max == p:\n",
      "                        candidates.append(c)\n",
      "        if candidates:\n",
      "            return candidates\n",
      "        else:\n",
      "            return [word]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(frequnecy.scan_and_compare_check_first_and_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def peter_norvig_approach(self, word):\n",
      "        if word in self.vocab:\n",
      "            return [word]\n",
      "        p_max = 0\n",
      "        approx = []\n",
      "        candidates = known_generated(word, self.vocab)\n",
      "        for c in candidates:\n",
      "            p = self.vocab[c]\n",
      "            if p > p_max:\n",
      "                p_max = p\n",
      "                approx = [c]\n",
      "            elif p == p_max:\n",
      "                approx.append(c)\n",
      "        if approx:\n",
      "            return approx\n",
      "        else:\n",
      "            return [word]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(frequnecy.peter_norvig_approach))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_accuracy(frequnecy.scan_and_compare, test_data, freq_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.1276747503566334\n",
      "CPU times: user 2min 9s, sys: 825 ms, total: 2min 10s\n",
      "Wall time: 8min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009747979077508321"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(frequnecy.scan_and_compare_check_first_and_last, test_data, freq_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.1276747503566334\n",
      "CPU times: user 2min 29s, sys: 1.13 s, total: 2min 30s\n",
      "Wall time: 2min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7063718497384689"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(frequnecy.peter_norvig_approach, test_data, freq_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pierwsze dwa modele mają jednak dość poważny problem, który nie został dotychczas jawnie wspomniany, ale jest dość nasuwający się.`\n",
    "\n",
    "`Nie znamy rozkładu generatora, przez co nie znamy` $P(w \\mid c)$,  `w powyższych dwóch modelach wzór na jego rozkład wziął się przecież znikąd.`<br>\n",
    "`Wcześniej nie musielismy się tym przejmować dlatego że wyrazy najbliższe zostały uważane za te mające największe prawdopodobieństo, nie musieliśmy znać ilościowego charakteru tego rozkładu. W tym przypadku całkowity rozkład nie zależy już tylko od rozkładu generatora, ale też od częstości występowania kandydata w języku, zależy więć od dwóch estymatorów` $P(w \\mid c), P(c)$.\n",
    "\n",
    "`Założenie o bliskości kandydata względem obserwowanego wyrazu wydaje się na tyle rozsądne by uzyskać zadowalający wynik, dlatego podejście Petera Norviga działa. Słowa w tym podejściu klastetyzują się względem metryki D-L i wybierana jest grupa o najmniejszej odległości, następnie spośród tej grupy wybierane jest najczęsciej występujące słowo.`<br>\n",
    "`Podejście użyte w kodzie numer 3 można zapisać jako:`\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w) = \\underset{c\\in C}{\\operatorname{argmax}}(\\underset{c\\in C}{\\operatorname{argmax}} P(w \\mid c)) * P(c)\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load syntetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Przypuśćmy jednak że chcieliśmy napisać \"thin\", ale napisaliśmy \"thinn\", w tym przypadku lepszym kandydatem dla ostatniego modelu jest \"think\", jako wyraz częściej występujący w słowniku.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_vocab[\"thin\"] < freq_vocab[\"think\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`By temu zapobiec możemy skorzystać ze sposobu posługiwania się danym wyrazem w języku. Możemy skorzystać z informacji zawartej w kontekście danego słowa`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Approches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`W tym podejściu wybieramy wyraz, na podstawie obserwacji wyrazu i jego kontekstu.`\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w_{1},w_{2})\n",
    "\\end{equation*}\n",
    "\n",
    "`gdzie` $w_{2}$ `jest wyrazem który zamierzamy sprawdzić, a` $w_{1}$ `wyrazem tworzącym kontekst`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\\\\\underset{c\\in C}{\\operatorname{argmax}} P(c \\mid w_{1},w_{2}) = \\underset{c\\in C}{\\operatorname{argmax}} \\frac{P(c, w_{1},w_{2})}{P(w_{1},w_{2})} = \\underset{c\\in C}{\\operatorname{argmax}} \\frac{P(w_{2} \\mid w_{1}, c) * P(c \\mid w_{1})}{P(w_{2} \\mid w_{1})} = \\\\\\underset{c\\in C}{\\operatorname{argmax}} P(w_{2} \\mid w_{1}, c) * P(c \\mid w_{1})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_approach_C import ContextApproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_BI_GRAMS = \"data/bigrams_final_encoded.pkl\"\n",
    "PATH_TO_TRI_GRAMS = \"data/trigrams_final_encoded.pkl\"\n",
    "PATH_TO_BI_GRAMS_TEST_DATA = \"data/bi_grams_test_data.csv\"\n",
    "PATH_TO_TRI_GRAMS_TEST_DATA = \"data/tri_grams_test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_bi = ContextApproach(load_bi_grams_path=PATH_TO_BI_GRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tri = ContextApproach(load_tri_grams_path=PATH_TO_TRI_GRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tri grams test data\n",
    "bi_grams_test_data = read_csv(PATH_TO_BI_GRAMS_TEST_DATA).values.tolist()[:10000]\n",
    "reduced_uni_grams_test_data_bi = context_bi.reduce_gram_test_data(bi_grams_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tri grams test data\n",
    "tri_grams_test_data = read_csv(PATH_TO_TRI_GRAMS_TEST_DATA).values.tolist()[:10000]\n",
    "reduced_bi_grams_test_data_tri = context_tri.reduce_gram_test_data(tri_grams_test_data)\n",
    "reduced_uni_grams_test_data_tri = context_tri.reduce_gram_test_data(reduced_bi_grams_test_data_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def context_approach_bigrams(self, utterance):\n",
      "        w1, w2 = word_tokenize(utterance)\n",
      "        c_based_on_context = self.bi_grams[w1]\n",
      "        if c_based_on_context:\n",
      "            vocab = {c for c in c_based_on_context}\n",
      "            candidates = known_generated(w2, vocab)\n",
      "            if candidates:\n",
      "                p_max = 0\n",
      "                approx = []\n",
      "                for c in candidates:\n",
      "                    p = c_based_on_context[c]\n",
      "                    if p_max < p:\n",
      "                        p_max = p\n",
      "                        approx = [c]\n",
      "                    elif p_max == p:\n",
      "                        approx.append(c)\n",
      "                return approx\n",
      "\n",
      "        return [\"xxxxx\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(context_tri.context_approach_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def context_approach_trigrams(self, utterance):\n",
      "        w1, w2, w3 = word_tokenize(utterance)\n",
      "        c_based_on_context = self.tri_grams[w1][w2]\n",
      "        if c_based_on_context:\n",
      "            vocab = {c for c in c_based_on_context}\n",
      "            candidates = known_generated(w3, vocab)\n",
      "            if candidates:\n",
      "                p_max = 0\n",
      "                approx = []\n",
      "                for c in candidates:\n",
      "                    p = c_based_on_context[c]\n",
      "                    if p_max < p:\n",
      "                        p_max = p\n",
      "                        approx = [c]\n",
      "                    elif p_max == p:\n",
      "                        approx.append(c)\n",
      "                return approx\n",
      "            \n",
      "        return [\"xxxxx\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(context_tri.context_approach_trigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark - TODO (lambda's pickle problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vocab = context_bi.get_vocab_for_bigram()\n",
    "get_accuracy(context_bi.context_approach_bigrams, bi_grams_test_data, vocab, threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vocab = context_tri.get_vocab_for_trigram(tri_grams)\n",
    "get_accuracy(context_tri.context_approach_trigrams, tri_grams_test_data, c, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntetic Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Porównywana będzie niestety tylko skuteczność z powodu problemów ze zrównoleglaniem działań przy użyciu defaultdicta w którym zgromadziliśmy ngramy.`<br>\n",
    "`Modele jednak róznią się tylko dostępem do większego słownika o drzewiastej strukturze.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [08:38<00:00, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2808\n",
      "CPU times: user 8min 33s, sys: 6.03 s, total: 8min 39s\n",
      "Wall time: 8min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "for pair in tqdm(tri_grams_test_data):\n",
    "    if pair[1] in context_tri.context_approach_trigrams(pair[0])[: 2]:\n",
    "        counter += 1\n",
    "print(counter/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YAYKS !!!\n",
    "`Zbyt mały zbiór tri-gramów, niestety większy nie mieści nam się w pamięci`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [10:01<00:00, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7858\n",
      "CPU times: user 9min 55s, sys: 7.69 s, total: 10min 2s\n",
      "Wall time: 10min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "for pair in tqdm(bi_grams_test_data):\n",
    "    if pair[1] in context_bi.context_approach_bigrams(pair[0])[: 2]:\n",
    "        counter += 1\n",
    "print(counter/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [10:45<00:00, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8582\n",
      "CPU times: user 10min 38s, sys: 8.26 s, total: 10min 46s\n",
      "Wall time: 10min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "for pair in tqdm(reduced_bi_grams_test_data_tri):\n",
    "    if pair[1] in context_bi.context_approach_bigrams(pair[0])[: 2]:\n",
    "        counter += 1\n",
    "print(counter/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bi = context_bi.get_vocab_for_bigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tri = context_tri.get_vocab_for_trigram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.0004\n",
      "CPU times: user 6min 14s, sys: 2.98 s, total: 6min 17s\n",
      "Wall time: 6min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6069"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(frequnecy.peter_norvig_approach, reduced_uni_grams_test_data_bi, vocab_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.0014\n",
      "CPU times: user 3min 52s, sys: 1.87 s, total: 3min 53s\n",
      "Wall time: 5min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6662"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(frequnecy.peter_norvig_approach, reduced_uni_grams_test_data_tri, vocab_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.0004\n",
      "CPU times: user 6min 18s, sys: 3.24 s, total: 6min 22s\n",
      "Wall time: 6min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4048"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(naive.generate_and_scan, reduced_uni_grams_test_data_bi, vocab_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of OOV:  0.0014\n",
      "CPU times: user 3min 53s, sys: 1.97 s, total: 3min 55s\n",
      "Wall time: 5min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4633"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_accuracy(naive.generate_and_scan, reduced_uni_grams_test_data_tri, vocab_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Przy prawdopodobieństwie warunkowym` $ P(w \\mid c) $ `uważamy wszystkie słowa` $\"c\"$ `o tej samej odległosci od` $\"w\"$ `za tak samo prawdopodobne. Ale nie wydaje się to być sprawiedliwe.`\n",
    "\n",
    "#### Oto przykład:\n",
    "`Niech` $w = abot$, `kandydatami równie prawdopodobnymi są słowa` $about$, $abbot$ `jak i` $bot$. `Opuszczenie` $\"u\"$ `albo drugiego` $\"b\"$ `wydaje się jednak bardziej prawdopodobne niż dodanie` $\"a\"$ `odległej na klawiaturze od` $\"b\"$ `o doraźną liczbę klawiszy.`\n",
    "`Z drugiej strony` $\"a\"$ `jest jednym z przedimków. Ktoś mógł chcieć napisać` $a$ $bot$, `ale zapomniał spacji, albo wstawił spację przed` $\"a\"$.\n",
    "\n",
    "`Rozkład rozmieszczenia literówek w napisie nie wydaje się również jednostajny, z tego co zaobserwowaliśmy na rzeczywistych danych, wśród słów nie zauważono literówek różniących się jednocześnie na pierwszym i ostatnim miejscu w słowie.\n",
    "Pokazuje to złożoność rozkładu generatora literówek. Systemy regułowe wydają się być najeżone wyjątkami w swoim podejściu do wyłapywania błędów.`<br>\n",
    "`Spróbujmy więc stworzyć narzędzie które będzie uczyło się tego rozkładu na podstawie danych - zbudujmy i wytrenujmy do tego celu sieć neuronową.`\n",
    "\n",
    "#### Tak jak wspomnieliśmy na wstępie, sieć będzie uczyła się jedynie na danych syntetycznych z powodu braku odpowiednio dużej liczby otagowanych danych rzeczywistych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
